{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/a1900001.1/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=5, padding=\"same\",\n",
    "                    input_shape=input_shape, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=5, padding=\"same\",\n",
    "                    activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation=\"relu\"))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset():\n",
    "    def __init__(self):\n",
    "        self.image_shape = (28,28,1)\n",
    "        self.num_classes = 10\n",
    "        \n",
    "    def get_batch(self):\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        \n",
    "        x_train, x_test = [self.preprocess(d) for d in [x_train, x_test]]\n",
    "        y_train, y_test = [self.preprocess(d, label_data=True) for d in [y_train, y_test]]\n",
    "        \n",
    "        return x_train, y_train, x_test, y_test\n",
    "    \n",
    "    def preprocess(self, data, label_data=False):\n",
    "        if label_data:\n",
    "            data = keras.utils.to_categorical(data, self.num_classes)\n",
    "        else:\n",
    "            data = data.astype(\"float32\")\n",
    "            data /= 255\n",
    "            shape = (data.shape[0], ) + self.image_shape\n",
    "            data = data.reshape(shape)\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, loss, optimizer):\n",
    "        self._target = model\n",
    "        self._target.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "        self.verbose = 1\n",
    "        self.log_dir = os.path.join(os.path.dirname('__file__'), 'logdir')\n",
    "    \n",
    "    def train(self, x_train, y_train, batch_size, epochs, validation_split):\n",
    "        if os.path.exists(self.log_dir):\n",
    "            import shutil\n",
    "            shutil.rmtree(self.log_dir)\n",
    "        os.mkdir(self.log_dir)\n",
    "        \n",
    "        self._target.fit(\n",
    "            x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "            validation_split=validation_split, callbacks=[TensorBoard(log_dir=self.log_dir)],\n",
    "            verbose=self.verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.1777 - acc: 0.9474 - val_loss: 0.0600 - val_acc: 0.9827\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 129s 3ms/step - loss: 0.0485 - acc: 0.9850 - val_loss: 0.0516 - val_acc: 0.9847\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 111s 2ms/step - loss: 0.0324 - acc: 0.9896 - val_loss: 0.0373 - val_acc: 0.9889\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.0241 - acc: 0.9925 - val_loss: 0.0359 - val_acc: 0.9895\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 147s 3ms/step - loss: 0.0164 - acc: 0.9945 - val_loss: 0.0380 - val_acc: 0.9897\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 134s 3ms/step - loss: 0.0145 - acc: 0.9951 - val_loss: 0.0424 - val_acc: 0.9880\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 149s 3ms/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.0413 - val_acc: 0.9895\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 156s 3ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0408 - val_acc: 0.9890\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 174s 4ms/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0555 - val_acc: 0.9881\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 142s 3ms/step - loss: 0.0077 - acc: 0.9970 - val_loss: 0.0357 - val_acc: 0.9912\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 135s 3ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0483 - val_acc: 0.9887\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 138s 3ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 0.0472 - val_acc: 0.9893\n",
      "Test loss: 0.034812863063834354\n",
      "Test accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "dataset = MNISTDataset()\n",
    "\n",
    "model = lenet(dataset.image_shape, dataset.num_classes)\n",
    "\n",
    "x_train, y_train, x_test, y_test = dataset.get_batch()\n",
    "trainer = Trainer(model, loss=\"categorical_crossentropy\", optimizer=Adam())\n",
    "trainer.train(x_train, y_train, batch_size=128, epochs=12, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
