{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/a1900001.1/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        32, kernel_size=3, padding=\"same\",\n",
    "        input_shape=input_shape, activation=\"relu\"\n",
    "        ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # classify the class by fully-connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_shape = (32, 32, 3)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def get_batch(self):\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "        x_train, x_test = [self.preprocess(d) for d in [x_train, x_test]]\n",
    "        y_train, y_test = [self.preprocess(d, label_data=True) for d in\n",
    "                           [y_train, y_test]]\n",
    "\n",
    "        return x_train, y_train, x_test, y_test\n",
    "\n",
    "    def preprocess(self, data, label_data=False):\n",
    "        if label_data:\n",
    "            data = keras.utils.to_categorical(data, self.num_classes)\n",
    "        else:\n",
    "            data = data.astype(\"float32\")\n",
    "            data /= 255  \n",
    "            shape = (data.shape[0],) + self.image_shape \n",
    "            data = data.reshape(shape)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\n",
    "    def __init__(self, model, loss, optimizer):\n",
    "        self._target = model\n",
    "        self._target.compile(\n",
    "            loss=loss, optimizer=optimizer, metrics=[\"accuracy\"]\n",
    "            )\n",
    "        self.verbose = 1\n",
    "        logdir = \"logdir_cifar10_net\"\n",
    "        self.log_dir = os.path.join(os.path.dirname('__file__'), 'logdir')\n",
    "        self.model_file_name = \"model_file.hdf5\"\n",
    "\n",
    "    def train(self, x_train, y_train, batch_size, epochs, validation_split):\n",
    "        if os.path.exists(self.log_dir):\n",
    "            import shutil\n",
    "            shutil.rmtree(self.log_dir)  \n",
    "        os.mkdir(self.log_dir)\n",
    "\n",
    "        model_path = os.path.join(self.log_dir, self.model_file_name)\n",
    "        self._target.fit(\n",
    "            x_train, y_train,\n",
    "            batch_size=batch_size, epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=[\n",
    "                TensorBoard(log_dir=self.log_dir),\n",
    "                ModelCheckpoint(model_path, save_best_only=True)\n",
    "            ],\n",
    "            verbose=self.verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 1.7858 - acc: 0.3623 - val_loss: 1.4229 - val_acc: 0.5100\n",
      "Epoch 2/12\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 1.3428 - acc: 0.5230 - val_loss: 1.1877 - val_acc: 0.5927\n",
      "Epoch 3/12\n",
      "40000/40000 [==============================] - 107s 3ms/step - loss: 1.1688 - acc: 0.5883 - val_loss: 1.0530 - val_acc: 0.6393\n",
      "Epoch 4/12\n",
      "40000/40000 [==============================] - 112s 3ms/step - loss: 1.0547 - acc: 0.6307 - val_loss: 1.0143 - val_acc: 0.6459\n",
      "Epoch 5/12\n",
      "40000/40000 [==============================] - 115s 3ms/step - loss: 0.9736 - acc: 0.6594 - val_loss: 0.9526 - val_acc: 0.6702\n",
      "Epoch 6/12\n",
      "40000/40000 [==============================] - 117s 3ms/step - loss: 0.9114 - acc: 0.6819 - val_loss: 0.9753 - val_acc: 0.6618\n",
      "Epoch 7/12\n",
      "40000/40000 [==============================] - 120s 3ms/step - loss: 0.8488 - acc: 0.7052 - val_loss: 1.0468 - val_acc: 0.6367\n",
      "Epoch 8/12\n",
      "40000/40000 [==============================] - 120s 3ms/step - loss: 0.8067 - acc: 0.7177 - val_loss: 0.8998 - val_acc: 0.6956\n",
      "Epoch 9/12\n",
      "40000/40000 [==============================] - 113s 3ms/step - loss: 0.7575 - acc: 0.7367 - val_loss: 0.8384 - val_acc: 0.7140\n",
      "Epoch 10/12\n",
      "40000/40000 [==============================] - 107s 3ms/step - loss: 0.7197 - acc: 0.7498 - val_loss: 0.8622 - val_acc: 0.7090\n",
      "Epoch 11/12\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 0.6787 - acc: 0.7623 - val_loss: 0.8733 - val_acc: 0.6999\n",
      "Epoch 12/12\n",
      "40000/40000 [==============================] - 105s 3ms/step - loss: 0.6452 - acc: 0.7774 - val_loss: 0.9199 - val_acc: 0.6897\n",
      "Test loss: 0.9452228118896484\n",
      "Test accuacy: 0.6825\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10Dataset()\n",
    "\n",
    "model = network(dataset.image_shape, dataset.num_classes)\n",
    "\n",
    "x_train, y_train, x_test, y_test = dataset.get_batch()\n",
    "trainer = Trainer(model, loss=\"categorical_crossentropy\", optimizer=RMSprop())\n",
    "trainer.train(x_train, y_train, batch_size=128, epochs=12, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0] )\n",
    "print(\"Test accuacy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
