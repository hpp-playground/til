{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/a1900001.1/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # extract image features by convolution and max pooling layers\n",
    "    model.add(Conv2D(\n",
    "        32, kernel_size=3, padding=\"same\",\n",
    "        input_shape=input_shape, activation=\"relu\"\n",
    "        ))\n",
    "    model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # classify the class by fully-connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_shape = (32, 32, 3)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def get_batch(self):\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "        x_train, x_test = [self.preprocess(d) for d in [x_train, x_test]]\n",
    "        y_train, y_test = [self.preprocess(d, label_data=True) for d in\n",
    "                           [y_train, y_test]]\n",
    "\n",
    "        return x_train, y_train, x_test, y_test\n",
    "\n",
    "    def preprocess(self, data, label_data=False):\n",
    "        if label_data:\n",
    "            # convert class vectors to binary class matrices\n",
    "            data = keras.utils.to_categorical(data, self.num_classes)\n",
    "        else:\n",
    "            data = data.astype(\"float32\")\n",
    "            data /= 255  # convert the value to 0~1 scale\n",
    "            shape = (data.shape[0],) + self.image_shape  # add dataset length\n",
    "            data = data.reshape(shape)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\n",
    "    def __init__(self, model, loss, optimizer):\n",
    "        self._target = model\n",
    "        self._target.compile(\n",
    "            loss=loss, optimizer=optimizer, metrics=[\"accuracy\"]\n",
    "            )\n",
    "        self.verbose = 1\n",
    "        logdir = \"logdir_cifar10_deep_with_aug\"\n",
    "        self.log_dir = os.path.join(os.path.dirname('__file__'), 'logdir')\n",
    "        self.model_file_name = \"model_file.hdf5\"\n",
    "\n",
    "    def train(self, x_train, y_train, batch_size, epochs, validation_split):\n",
    "        if os.path.exists(self.log_dir):\n",
    "            import shutil\n",
    "            shutil.rmtree(self.log_dir)\n",
    "        os.mkdir(self.log_dir)\n",
    "\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (0~180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally\n",
    "            height_shift_range=0.1,  # randomly shift images vertically\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "        datagen.fit(x_train)\n",
    "\n",
    " \n",
    "        indices = np.arange(x_train.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        validation_size = int(x_train.shape[0] * validation_split)\n",
    "        x_train, x_valid = x_train[indices[:-validation_size], :], x_train[indices[-validation_size:], :]\n",
    "        y_train, y_valid = y_train[indices[:-validation_size], :], y_train[indices[-validation_size:], :]\n",
    "\n",
    "        model_path = os.path.join(self.log_dir, self.model_file_name)\n",
    "        \n",
    "        self._target.fit_generator(\n",
    "            datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_valid, y_valid),\n",
    "            callbacks=[\n",
    "                TensorBoard(log_dir=self.log_dir),\n",
    "                ModelCheckpoint(model_path, save_best_only=True)\n",
    "            ],\n",
    "            verbose=self.verbose,\n",
    "            workers=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "312/312 [==============================] - 188s 604ms/step - loss: 1.9050 - acc: 0.3048 - val_loss: 1.4411 - val_acc: 0.4868\n",
      "Epoch 2/15\n",
      "312/312 [==============================] - 239s 765ms/step - loss: 1.5304 - acc: 0.4518 - val_loss: 1.2794 - val_acc: 0.5606\n",
      "Epoch 3/15\n",
      "312/312 [==============================] - 268s 860ms/step - loss: 1.3588 - acc: 0.5143 - val_loss: 1.1668 - val_acc: 0.5848\n",
      "Epoch 4/15\n",
      "312/312 [==============================] - 281s 900ms/step - loss: 1.2454 - acc: 0.5631 - val_loss: 1.1259 - val_acc: 0.5949\n",
      "Epoch 5/15\n",
      "312/312 [==============================] - 263s 842ms/step - loss: 1.1640 - acc: 0.5888 - val_loss: 1.0057 - val_acc: 0.6467\n",
      "Epoch 6/15\n",
      "312/312 [==============================] - 258s 828ms/step - loss: 1.0857 - acc: 0.6210 - val_loss: 0.8653 - val_acc: 0.6922\n",
      "Epoch 7/15\n",
      "312/312 [==============================] - 259s 831ms/step - loss: 1.0413 - acc: 0.6343 - val_loss: 0.8753 - val_acc: 0.6986\n",
      "Epoch 8/15\n",
      "312/312 [==============================] - 256s 822ms/step - loss: 0.9938 - acc: 0.6531 - val_loss: 0.8288 - val_acc: 0.7091\n",
      "Epoch 9/15\n",
      "312/312 [==============================] - 258s 826ms/step - loss: 0.9674 - acc: 0.6666 - val_loss: 0.7636 - val_acc: 0.7308\n",
      "Epoch 10/15\n",
      "312/312 [==============================] - 257s 825ms/step - loss: 0.9338 - acc: 0.6744 - val_loss: 0.8174 - val_acc: 0.7143\n",
      "Epoch 11/15\n",
      "312/312 [==============================] - 256s 822ms/step - loss: 0.9217 - acc: 0.6810 - val_loss: 0.7312 - val_acc: 0.7464\n",
      "Epoch 12/15\n",
      "312/312 [==============================] - 259s 829ms/step - loss: 0.8935 - acc: 0.6890 - val_loss: 0.8341 - val_acc: 0.7230\n",
      "Epoch 13/15\n",
      "312/312 [==============================] - 258s 828ms/step - loss: 0.8843 - acc: 0.6941 - val_loss: 0.6974 - val_acc: 0.7636\n",
      "Epoch 14/15\n",
      "312/312 [==============================] - 256s 820ms/step - loss: 0.8716 - acc: 0.7013 - val_loss: 0.7342 - val_acc: 0.7473\n",
      "Epoch 15/15\n",
      "312/312 [==============================] - 258s 827ms/step - loss: 0.8575 - acc: 0.7045 - val_loss: 0.8630 - val_acc: 0.7272\n",
      "Test loss: 0.8884348275184631\n",
      "Test accuacy: 0.7203\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10Dataset()\n",
    "\n",
    "model = network(dataset.image_shape, dataset.num_classes)\n",
    "\n",
    "x_train, y_train, x_test, y_test = dataset.get_batch()\n",
    "trainer = Trainer(model, loss=\"categorical_crossentropy\", optimizer=RMSprop())\n",
    "trainer.train(x_train, y_train, batch_size=128, epochs=15, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0] )\n",
    "print(\"Test accuacy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
